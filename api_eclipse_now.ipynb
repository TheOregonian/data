{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import googlemaps\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal\n",
    "\n",
    "Retrieve up-to-date travel time data for the most efficient route between a series of cities, transform it, and send it to Google Sheets to feed a Tableau workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key=os.getenv('GMAPS_DISTANCE_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origins = ['Portland, OR, USA',\n",
    "           'Lincoln City, OR, USA',\n",
    "           'Oregon City, OR, USA',\n",
    "           'Boise, ID, USA']\n",
    "destinations = ['Salem, OR, USA',\n",
    "                'Corvallis, OR, USA',\n",
    "                'Madras, OR, USA',\n",
    "                'Baker City, OR, USA',\n",
    "               'Lincoln City, OR, USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = gmaps.distance_matrix(origins=origins,\n",
    "                                destinations=destinations,\n",
    "                                units='imperial',\n",
    "                                departure_time='now',\n",
    "                                traffic_model='best_guess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to parse the results json for easy conversion to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for i, origin in enumerate(origins):\n",
    "    for j, destination in enumerate(destinations):\n",
    "        fun_dict = {'origin':origin,\n",
    "                   'destination': destination}\n",
    "        intermediate_thing = results['rows'][i]['elements'][j]\n",
    "        for key,value in intermediate_thing.items():\n",
    "            if (key == 'status'):\n",
    "                continue\n",
    "            fun_dict.update({key: value['value']})\n",
    "        new_rows.append(fun_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform calculations to more intuitively display time information (returned by the API in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['duration formatted'] = round(df['duration']/3600,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['traffic_duration formatted'] = round(df['duration_in_traffic']/3600,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['difference'] = round(df['duration_in_traffic']/df['duration'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplify city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['destination'] = df['destination'].apply(lambda x: x.split(\",\")[0])\n",
    "df['origin'] = df['origin'].apply(lambda x: x.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop([6,7,8,9,11,12,13,14,15,16,17,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = df[['destination','origin','duration formatted',\n",
    "               'traffic_duration formatted','difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df.rename(columns={\n",
    "        'destination':'To',\n",
    "        'origin':'From',\n",
    "        'duration formatted':'Typical Travel Time (Hours)',\n",
    "        'traffic_duration formatted':'Current Travel Time (Hours)',\n",
    "        'difference':'Difference'\n",
    "    },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wks = gc.open(\"eclipse_traffic\").sheet1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell is code adapted from the df2gspread library, which could not load my credentials for reasons I've yet to debug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grouper(n, iterable):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adapted from the df2gspread library, which could not load my credentials\n",
    "def upload(df, wks, chunk_size=1000,\n",
    "           col_names=True, row_names=True, clean=True, credentials=None,\n",
    "           start_cell = 'A1', df_size = False, new_sheet_dimensions = (1000,100)):\n",
    "    '''\n",
    "        Upload given Pandas DataFrame to Google Drive and returns \n",
    "        gspread Worksheet object\n",
    "\n",
    "        :param df: Pandas DataFrame\n",
    "        :param gfile: path to Google Spreadsheet or gspread ID\n",
    "        :param wks_name: worksheet name\n",
    "        :param chunk_size: size of chunk to upload\n",
    "        :param col_names: passing top row to column names for Pandas DataFrame\n",
    "        :param row_names: passing left column to row names for Pandas DataFrame\n",
    "        :param clean: clean all data in worksheet before uploading \n",
    "        :param credentials: provide own credentials\n",
    "        :param start_cell: specify where to insert the DataFrame; default is A1\n",
    "        :param df_size: \n",
    "            -If True and worksheet name does NOT exist, will create \n",
    "            a new worksheet that is the size of the df; otherwise, by default, \n",
    "            creates sheet of 1000x100 cells. \n",
    "            -If True and worksheet does exist, will resize larger or smaller to \n",
    "            fit new dataframe. \n",
    "            -If False and dataframe is larger than existing sheet, will resize \n",
    "            the sheet larger.\n",
    "            -If False and dataframe is smaller than existing sheet, does not resize.\n",
    "        :param new_sheet_dimensions: tuple of (row, cols) for size of a new sheet\n",
    "        :type df: class 'pandas.core.frame.DataFrame'\n",
    "        :type gfile: str\n",
    "        :type wks_name: str\n",
    "        :type chunk_size: int\n",
    "        :type col_names: bool\n",
    "        :type row_names: bool\n",
    "        :type clean: bool\n",
    "        :type credentials: class 'oauth2client.client.OAuth2Credentials'\n",
    "        :type start_cell: str\n",
    "        :type df_size: bool\n",
    "        :type new_sheet_dimensions: tuple\n",
    "        :returns: gspread Worksheet\n",
    "        :rtype: class 'gspread.models.Worksheet'\n",
    "\n",
    "        :Example:\n",
    "\n",
    "            >>> from df2gspread import df2gspread as d2g\n",
    "            >>> import pandas as pd\n",
    "            >>> df = pd.DataFrame([1 2 3])\n",
    "            >>> wks = d2g.upload(df, wks_name='Example worksheet')\n",
    "            >>> wks.title\n",
    "            'Example worksheet'\n",
    "    '''\n",
    "    # access credentials\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name('client_secret.json', scope)\n",
    "    # auth for gspread\n",
    "    gc = gspread.authorize(credentials)\n",
    "\n",
    "    start_col = re.split('(\\d+)',start_cell)[0].upper()\n",
    "    start_row = re.split('(\\d+)',start_cell)[1]\n",
    "    start_row_int, start_col_int = wks.get_int_addr(start_cell)\n",
    "\n",
    "    # find last index and column name (A B ... Z AA AB ... AZ BA)\n",
    "    num_rows = len(df.index) + 1 if col_names else len(df.index)\n",
    "    last_idx_adjust = start_row_int - 1\n",
    "    last_idx = num_rows + last_idx_adjust\n",
    "\n",
    "    num_cols = len(df.columns) + 1 if row_names else len(df.columns)\n",
    "    last_col_adjust = start_col_int - 1\n",
    "    last_col_int = num_cols + last_col_adjust\n",
    "    last_col = re.split('(\\d+)',(wks.get_addr_int(1, last_col_int)))[0].upper()\n",
    "\n",
    "    # If user requested to resize sheet to fit dataframe, go ahead and \n",
    "    # resize larger or smaller to better match new size of pandas dataframe.\n",
    "    # Otherwise, leave it the same size unless the sheet needs to be expanded\n",
    "    # to accomodate a larger dataframe.\n",
    "    if df_size:\n",
    "        wks.resize(rows=len(df.index) + col_names, cols=len(df.columns) + row_names)\n",
    "    if len(df.index) + col_names + last_idx_adjust > wks.row_count:\n",
    "        wks.add_rows(len(df.index) - wks.row_count + col_names + last_idx_adjust)\n",
    "    if len(df.columns) + row_names + last_col_adjust  > wks.col_count:\n",
    "        wks.add_cols(len(df.columns) - wks.col_count + row_names + last_col_adjust)\n",
    "\n",
    "    # Define first cell for rows and columns\n",
    "    first_col = re.split('(\\d+)',(wks.get_addr_int(1, start_col_int + 1)))[0].upper() if row_names else start_col\n",
    "    first_row = str(start_row_int + 1) if col_names else start_row\n",
    "\n",
    "    # Addition of col names\n",
    "    if col_names:\n",
    "        cell_list = wks.range('%s%s:%s%s' % (first_col, start_row, last_col, start_row))\n",
    "        for idx, cell in enumerate(cell_list):\n",
    "            cell.value = df.columns.values[idx]\n",
    "        wks.update_cells(cell_list)\n",
    "\n",
    "    # Addition of row names\n",
    "    if row_names:\n",
    "        cell_list = wks.range('%s%s:%s%d' % (start_col, first_row, start_col, last_idx))\n",
    "        for idx, cell in enumerate(cell_list):\n",
    "            cell.value = df.index[idx]\n",
    "        wks.update_cells(cell_list)\n",
    "\n",
    "    # Addition of cell values\n",
    "    cell_list = wks.range('%s%s:%s%d' % (\n",
    "        first_col, first_row, last_col, last_idx))\n",
    "    for j, idx in enumerate(df.index):\n",
    "        for i, col in enumerate(df.columns.values):\n",
    "            cell_list[i + j * len(df.columns.values)].value = df[col][idx]\n",
    "    for cells in grouper(chunk_size, cell_list):\n",
    "        wks.update_cells(list(cells))\n",
    "\n",
    "    return wks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upload(df=final_df,wks=wks,credentials=credentials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
